{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4acd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gumma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:41: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  _CPU_DEVICES = (\"cpu\", torch.device(\"cpu\"))\n",
      "Global seed set to 101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torchcrf import CRF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from utils_bert import get_encoded_input\n",
    "from metrics import f1score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from multiprocessing import cpu_count\n",
    "from os import environ\n",
    "from platform import system\n",
    "\n",
    "environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pl.seed_everything(seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675f0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2.75e-5\n",
    "BATCH_SIZE = 20\n",
    "WEIGHT_DECAY = 1e-2\n",
    "EPOCHS = 25\n",
    "N_JOBS = cpu_count() if system() != \"Windows\" else 0\n",
    "\n",
    "BERT_TYPE = \"roberta-base\"\n",
    "# tag2idx = {'B': 0, 'I': 1, 'O': 2, 'E': 3, 'S': 4, 'X': 5}\n",
    "tag2idx = {'B': 0, 'I': 1, 'O': 2, 'E': 3, 'S': 4, '<': 5, \">\":6, \"$\": 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8793db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4NER(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 bert_type=BERT_TYPE, \n",
    "                 num_tags=len(tag2idx), \n",
    "                 warmup_steps=0, \n",
    "                 total_steps=1024,\n",
    "                 train_dataset=None,\n",
    "                 val_dataset=None,\n",
    "                 test_dataset=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(bert_type)\n",
    "        self.crf = CRF(num_tags=num_tags, batch_first=True)\n",
    "        self.fc = nn.Linear(768, num_tags)\n",
    "        ## Hyperparameters ##\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.weight_decay = WEIGHT_DECAY\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        ## Datasets ##\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, \n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_JOBS,\n",
    "                          drop_last=False)\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, \n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=N_JOBS,\n",
    "                          drop_last=False)\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, \n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=N_JOBS,\n",
    "                          drop_last=False)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        out = self.bert(input_ids, attention_masks).last_hidden_state\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def _shared_evaluation_step(self, batch, batch_idx):\n",
    "        ids, masks, lbls = batch\n",
    "        emissions = self(ids, masks)\n",
    "        loss = -self.crf(emissions, lbls, mask=masks)\n",
    "        pred = self.crf.decode(emissions, mask=masks)\n",
    "        r, p, f1 = f1score(lbls, pred)\n",
    "        return loss, r, p, f1\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, r, p, f1 = self._shared_evaluation_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_recall\", r, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_precision\", p, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1score\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, r, p, f1 = self._shared_evaluation_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_recall\", r, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_precision\", p, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1score\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, r, p, f1 = self._shared_evaluation_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_recall\", r, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_precision\", p, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_f1score\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        ids, masks = batch \n",
    "        return self.crf.decode(self(ids, masks), mask=masks)\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), \n",
    "                          lr=self.learning_rate,\n",
    "                          amsgrad=True,\n",
    "                          weight_decay=self.weight_decay)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,\n",
    "                                                    num_warmup_steps=self.warmup_steps,\n",
    "                                                    num_training_steps=self.total_steps)\n",
    "\n",
    "        lr_scheduler = {\n",
    "            'scheduler': scheduler, \n",
    "            'interval': 'epoch', \n",
    "            'frequency': 1\n",
    "        }\n",
    "        \n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5875c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input, extended_labels = get_encoded_input(\"../data/train_290818.txt\", tag2idx=tag2idx, tokenizer_name=BERT_TYPE)\n",
    "\n",
    "L = len(extended_labels)\n",
    "\n",
    "dataset = TensorDataset(torch.LongTensor(encoded_input[\"input_ids\"]),\n",
    "                        torch.BoolTensor(encoded_input[\"attention_mask\"]),\n",
    "                        torch.LongTensor(extended_labels))\n",
    "\n",
    "train_sz, val_sz = L-int(0.1*L), int(0.1*L)\n",
    "train_dataset, val_dataset = random_split(dataset, (train_sz, val_sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d9705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input, extended_labels = get_encoded_input(\"../data/test_290818.txt\", tag2idx=tag2idx, tokenizer_name=BERT_TYPE)\n",
    "\n",
    "test_dataset = TensorDataset(torch.LongTensor(encoded_input[\"input_ids\"]),\n",
    "                             torch.BoolTensor(encoded_input[\"attention_mask\"]),\n",
    "                             torch.LongTensor(extended_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e51b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_RATIO = 0.05\n",
    "TOTAL_STEPS = len(train_dataset) // BATCH_SIZE\n",
    "WARMUP_STEPS = int(WARMUP_RATIO * TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328834d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = BERT4NER(bert_type=BERT_TYPE,\n",
    "                 warmup_steps=WARMUP_STEPS,\n",
    "                 total_steps=TOTAL_STEPS,\n",
    "                 train_dataset=train_dataset,\n",
    "                 val_dataset=val_dataset,\n",
    "                 test_dataset=test_dataset)\n",
    "\n",
    "\n",
    "earlystopping_callback = EarlyStopping(monitor=\"val_f1score\", \n",
    "                                       min_delta=1e-4, \n",
    "                                       patience=5, \n",
    "                                       mode=\"max\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"./\",\n",
    "                                      filename=f\"{BERT_TYPE}-ner-val-f1score\",\n",
    "                                      save_top_k=1, \n",
    "                                      mode=\"max\",\n",
    "                                      monitor=\"val_f1score\",\n",
    "                                      save_weights_only=True)\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                     max_epochs=EPOCHS,\n",
    "                     precision=16,\n",
    "                     log_every_n_steps=1,\n",
    "                     callbacks=[earlystopping_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72fe7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: d:\\Suggestion-Mining-from-Noisy-Data\\src_feat\\lightning_logs\n",
      "c:\\Users\\gumma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: UserWarning: Checkpoint directory D:\\Suggestion-Mining-from-Noisy-Data\\src_feat exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type         | Params\n",
      "--------------------------------------\n",
      "0 | bert | RobertaModel | 124 M \n",
      "1 | crf  | CRF          | 80    \n",
      "2 | fc   | Linear       | 6.2 K \n",
      "--------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "249.304   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1323a167ee949b58b89f39fb31bbf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gumma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\gumma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c483fab70fe46be9a0437050e9f9737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9839b8b689b34f848a253534c18b0e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038f6878c6a141a69e0a907da8a67e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1b36e9143e4b95ae6f530c11774994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70cdc223eef4f28a9da73d8122ec589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a9481270a14f14ad3331b5e48a10f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954ba5435f9c4245a927116eba029d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e570cab7fa6649999ad30dc292443347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1959dca899e64746a4073cb714ae122a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdb888d2719416eb70920511e11b406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dd8630eacf4878ba58233399611ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86204a0154046d99c306988c49e32e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f352ec09ec2430aa2099c97aa47ea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0475211bd47b4c1abedd856bd4535e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38166cbd9e5945f1ab67ca7223ac39f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6aa7df2bd93409995ae6c2e185c51d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719a7f2452014a71a5cc973a3fe937a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a23670d02684e3d8a0aeee9124c2f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3ab9873fe149babe68e1b53c7ade26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6113b19b372465b9ae8aaa25fc5f5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c04fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\gumma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f280e3ea16247f5a1aff2a30f2db10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5408464670181274     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         144.6875          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4905465841293335     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6255844831466675     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5408464670181274    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        144.6875         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4905465841293335    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6255844831466675    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 144.6875,\n",
       "  'test_recall': 0.6255844831466675,\n",
       "  'test_precision': 0.4905465841293335,\n",
       "  'test_f1score': 0.5408464670181274}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"./{BERT_TYPE}-ner-val-f1score.ckpt\")[\"state_dict\"])\n",
    "trainer.test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a2000831a5050d8503f24d6733c4641a8734e9c81b6dced7c2deb928c6c3201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
